{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intial imports: \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "# import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "# import streamlit as st\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up the necessary files for data transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_file(csv_file):\n",
    "    rows = []\n",
    "    #creating empty file in folder, i added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    # csv_file = f\"/users/aly/documents/programming/apps/machine learning/asl converter/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # csv_file=\"d:/personnel/other learning/programming/personal_projects/asl_language_translation/training_models/mediapipe/demo_test/demo.csv\"\n",
    "    # if os.path.exists(csv_file):\n",
    "    #     return \n",
    "\n",
    "\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    num_coords = 21 + 21 #+ 33\n",
    "    landmarks = []\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val)]#.format(val), 'z{}'.format(val)]#, 'v{}'.format(val)]\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting the hand coordinates: \n",
    "###### https://arkalsekar.medium.com/how-to-get-all-the-co-ordinates-of-hand-using-mediapipe-hand-solutions-ac7e2742f702\n",
    "###### https://www.futurelearn.com/info/courses/introduction-to-image-analysis-for-plant-phenotyping/0/steps/305359\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cam(csv_file, num_val = 1):   \n",
    "  rows = []\n",
    "  index = 0\n",
    "  # For webcam input:\n",
    "  cap = cv2.VideoCapture(0)\n",
    "  with mp_hands.Hands(\n",
    "      min_detection_confidence=0.5,\n",
    "      min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "      success, image = cap.read()\n",
    "      if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "\n",
    "      # Flip the image horizontally for a later selfie-view display, and convert\n",
    "      # the BGR image to RGB.\n",
    "      image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "      # To improve performance, optionally mark the image as not writeable to\n",
    "      # pass by reference.\n",
    "      image.flags.writeable = False\n",
    "\n",
    "      #!results contains all the information about the image, in this case, we are looking at hands\n",
    "      results = hands.process(image)\n",
    "      \n",
    "      image_height, image_width, _ = image.shape\n",
    "      # Draw the hand annotations on the image.\n",
    "      image.flags.writeable = True\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "      \n",
    "      #stop the process\n",
    "      if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "          break\n",
    "      \n",
    "      # print(type(results.multi_hand_landmarks))\n",
    "      # print('-'*50, '\\n', results.multi_hand_landmarks)\n",
    "      \n",
    "      # #!checks for both hands, and looks if there is data\n",
    "      # if results.multi_hand_landmarks:\n",
    "      #   #!extracting the information from the right hand\n",
    "      #   for hand in results.multi_hand_landmarks:\n",
    "\n",
    "      #     both_hand = hand\n",
    "      #     hand_row = list(np.array([[landmark.x, landmark.y] for ids, landmark in both_hand]).flatten())\n",
    "\n",
    "      if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "          empty_row = []\n",
    "          # Here is How to Get All the Coordinates\n",
    "          for ids, landmrk in enumerate(hand_landmarks.landmark):\n",
    "              # print(ids, landmrk)\n",
    "              cx, cy= landmrk.x * image_width, landmrk.y*image_height, #landmrk.z\n",
    "              empty_row.append(cx)\n",
    "              empty_row.append(cy)\n",
    "              # empty_row.append(cz)\n",
    "              # print(cx, cy)\n",
    "          mp_drawing.draw_landmarks(\n",
    "              image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "          if index % num_val == 0:\n",
    "            rows.append(empty_row)\n",
    "          index += 1\n",
    "          # print(len(empty_row))\n",
    "        # #!else, I wanna just write 0 for the information about the hands.\n",
    "      # else:\n",
    "      #   #skip what is not usefulq \n",
    "      # #   both_hand_row = list(np.array([[0,0] for i in range(42)]).flatten())\n",
    "      #   # empty_row = [0 for i in range(42)]\n",
    "      #   # rows.append(empty_row)\n",
    "      #   continue\n",
    "\n",
    "      #!this is what shows the hands\n",
    "      cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "  # After the loop release the cap object \n",
    "  cap.release() \n",
    "\n",
    "  #closes all instance of the camera\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "  with open(csv_file, mode='a', newline='') as f:\n",
    "                        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        for row in rows:\n",
    "                            csv_writer.writerow(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the opencv library \n",
    "# import cv2 \n",
    "  \n",
    "  \n",
    "# # define a video capture object \n",
    "# vid = cv2.VideoCapture(0) \n",
    "  \n",
    "# while(True): \n",
    "      \n",
    "#     # Capture the video frame \n",
    "#     # by frame \n",
    "#     ret, frame = vid.read() \n",
    "  \n",
    "#     # Display the resulting frame \n",
    "#     cv2.imshow('frame', frame) \n",
    "\n",
    "#     #extracting the frames  \n",
    "    \n",
    "    \n",
    "\n",
    "#     # the 'q' button is set as the \n",
    "#     # quitting button you may use any \n",
    "#     # desired button of your choice \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "#         break\n",
    "  \n",
    "# # After the loop release the cap object \n",
    "# vid.release() \n",
    "# # Destroy all the windows \n",
    "# cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
