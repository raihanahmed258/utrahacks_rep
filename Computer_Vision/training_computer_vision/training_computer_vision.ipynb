{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### work in this repository was inspired by \n",
    "##### https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe/blob/main/README_EN.md\n",
    "##### https://www.youtube.com/watch?v=a99p_fAr6e4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# this is just to make sure that the results are reproducible to anyone that runs the code lol.\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data formatting\n",
    "https://devqa.io/python-convert-csv-file-to-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "['data/train/start/start26.csv', 'data/train/start/start44.csv', 'data/train/start/start0.csv', 'data/train/start/start1.csv', 'data/train/start/start10.csv', 'data/train/start/start11.csv', 'data/train/start/start12.csv', 'data/train/start/start13.csv', 'data/train/start/start14.csv', 'data/train/start/start15.csv', 'data/train/start/start16.csv', 'data/train/start/start17.csv', 'data/train/start/start18.csv', 'data/train/start/start19.csv', 'data/train/start/start2.csv', 'data/train/start/start20.csv', 'data/train/start/start21.csv', 'data/train/start/start22.csv', 'data/train/start/start23.csv', 'data/train/start/start24.csv', 'data/train/start/start25.csv', 'data/train/start/start27.csv', 'data/train/start/start28.csv', 'data/train/start/start29.csv', 'data/train/start/start3.csv', 'data/train/start/start30.csv', 'data/train/start/start31.csv', 'data/train/start/start32.csv', 'data/train/start/start33.csv', 'data/train/start/start34.csv', 'data/train/start/start35.csv', 'data/train/start/start36.csv', 'data/train/start/start37.csv', 'data/train/start/start38.csv', 'data/train/start/start39.csv', 'data/train/start/start4.csv', 'data/train/start/start40.csv', 'data/train/start/start41.csv', 'data/train/start/start42.csv', 'data/train/start/start43.csv', 'data/train/start/start45.csv', 'data/train/start/start46.csv', 'data/train/start/start47.csv', 'data/train/start/start48.csv', 'data/train/start/start49.csv', 'data/train/start/start5.csv', 'data/train/start/start50.csv', 'data/train/start/start51.csv', 'data/train/start/start52.csv', 'data/train/start/start53.csv', 'data/train/start/start54.csv', 'data/train/start/start55.csv', 'data/train/start/start56.csv', 'data/train/start/start57.csv', 'data/train/start/start58.csv', 'data/train/start/start59.csv', 'data/train/start/start6.csv', 'data/train/start/start7.csv', 'data/train/start/start8.csv', 'data/train/start/start9.csv']\n",
      "60\n",
      "[218.47599029541016, 321.2573719024658, 201.79677963256836, 279.15693283081055, 212.06871032714844, 230.42837619781494, 228.4135627746582, 197.6455307006836, 231.85338973999023, 171.25462532043457, 260.26561737060547, 215.46100616455078, 274.827880859375, 177.4298858642578, 285.3101348876953, 155.1402711868286, 296.51636123657227, 137.72432327270508, 284.9685287475586, 229.32503700256348, 316.0531425476074, 194.67727661132812, 335.6250762939453, 173.0332374572754, 352.27794647216797, 155.8568572998047, 300.217227935791, 249.1355037689209, 333.4811782836914, 222.57554054260254, 352.3426818847656, 204.99325275421143, 368.25252532958984, 188.81452560424805, 308.0757141113281, 273.28471183776855, 339.2759323120117, 260.8761978149414, 359.7352600097656, 252.32128143310547, 377.67635345458984, 243.07233810424805]\n",
      "training set:\n",
      "1045\n",
      "1045\n",
      "turn\n",
      "['data/train/turn/turn26.csv', 'data/train/turn/turn44.csv', 'data/train/turn/turn0.csv', 'data/train/turn/turn1.csv', 'data/train/turn/turn10.csv', 'data/train/turn/turn11.csv', 'data/train/turn/turn12.csv', 'data/train/turn/turn13.csv', 'data/train/turn/turn14.csv', 'data/train/turn/turn15.csv', 'data/train/turn/turn16.csv', 'data/train/turn/turn17.csv', 'data/train/turn/turn18.csv', 'data/train/turn/turn19.csv', 'data/train/turn/turn2.csv', 'data/train/turn/turn20.csv', 'data/train/turn/turn21.csv', 'data/train/turn/turn22.csv', 'data/train/turn/turn23.csv', 'data/train/turn/turn24.csv', 'data/train/turn/turn25.csv', 'data/train/turn/turn27.csv', 'data/train/turn/turn28.csv', 'data/train/turn/turn29.csv', 'data/train/turn/turn3.csv', 'data/train/turn/turn30.csv', 'data/train/turn/turn31.csv', 'data/train/turn/turn32.csv', 'data/train/turn/turn33.csv', 'data/train/turn/turn34.csv', 'data/train/turn/turn35.csv', 'data/train/turn/turn36.csv', 'data/train/turn/turn37.csv', 'data/train/turn/turn38.csv', 'data/train/turn/turn39.csv', 'data/train/turn/turn4.csv', 'data/train/turn/turn40.csv', 'data/train/turn/turn41.csv', 'data/train/turn/turn42.csv', 'data/train/turn/turn43.csv', 'data/train/turn/turn45.csv', 'data/train/turn/turn46.csv', 'data/train/turn/turn47.csv', 'data/train/turn/turn48.csv', 'data/train/turn/turn49.csv', 'data/train/turn/turn5.csv', 'data/train/turn/turn50.csv', 'data/train/turn/turn51.csv', 'data/train/turn/turn52.csv', 'data/train/turn/turn53.csv', 'data/train/turn/turn54.csv', 'data/train/turn/turn55.csv', 'data/train/turn/turn56.csv', 'data/train/turn/turn57.csv', 'data/train/turn/turn58.csv', 'data/train/turn/turn59.csv', 'data/train/turn/turn6.csv', 'data/train/turn/turn7.csv', 'data/train/turn/turn8.csv', 'data/train/turn/turn9.csv']\n",
      "60\n",
      "[279.60174560546875, 263.76874923706055, 245.0604248046875, 256.99170112609863, 215.73675155639648, 230.05722999572754, 213.9126968383789, 197.6400089263916, 235.23239135742188, 190.21625518798828, 232.39931106567383, 204.30696487426758, 223.8076400756836, 185.65741539001465, 229.6152114868164, 209.56645488739014, 234.06299591064453, 215.93439102172852, 251.66122436523438, 200.36438941955566, 242.53662109375, 183.1774663925171, 246.92373275756836, 211.8261194229126, 251.796875, 214.66941833496094, 270.2850914001465, 199.30644035339355, 261.99520111083984, 182.11953163146973, 264.7813415527344, 211.65441513061523, 269.8749542236328, 216.56939506530762, 290.8381462097168, 199.5754909515381, 280.85460662841797, 187.25805759429932, 281.2198066711426, 208.05357456207275, 286.7642402648926, 213.23664665222168]\n",
      "training set:\n",
      "2232\n",
      "2232\n",
      "grapple\n",
      "['data/train/grapple/grapple24.csv', 'data/train/grapple/grapple40.csv', 'data/train/grapple/grapple0.csv', 'data/train/grapple/grapple1.csv', 'data/train/grapple/grapple10.csv', 'data/train/grapple/grapple11.csv', 'data/train/grapple/grapple12.csv', 'data/train/grapple/grapple13.csv', 'data/train/grapple/grapple14.csv', 'data/train/grapple/grapple15.csv', 'data/train/grapple/grapple16.csv', 'data/train/grapple/grapple17.csv', 'data/train/grapple/grapple18.csv', 'data/train/grapple/grapple19.csv', 'data/train/grapple/grapple2.csv', 'data/train/grapple/grapple20.csv', 'data/train/grapple/grapple21.csv', 'data/train/grapple/grapple22.csv', 'data/train/grapple/grapple23.csv', 'data/train/grapple/grapple25.csv', 'data/train/grapple/grapple26.csv', 'data/train/grapple/grapple27.csv', 'data/train/grapple/grapple28.csv', 'data/train/grapple/grapple29.csv', 'data/train/grapple/grapple3.csv', 'data/train/grapple/grapple30.csv', 'data/train/grapple/grapple31.csv', 'data/train/grapple/grapple32.csv', 'data/train/grapple/grapple33.csv', 'data/train/grapple/grapple34.csv', 'data/train/grapple/grapple35.csv', 'data/train/grapple/grapple36.csv', 'data/train/grapple/grapple37.csv', 'data/train/grapple/grapple38.csv', 'data/train/grapple/grapple39.csv', 'data/train/grapple/grapple4.csv', 'data/train/grapple/grapple41.csv', 'data/train/grapple/grapple42.csv', 'data/train/grapple/grapple43.csv', 'data/train/grapple/grapple44.csv', 'data/train/grapple/grapple45.csv', 'data/train/grapple/grapple46.csv', 'data/train/grapple/grapple47.csv', 'data/train/grapple/grapple48.csv', 'data/train/grapple/grapple49.csv', 'data/train/grapple/grapple5.csv', 'data/train/grapple/grapple50.csv', 'data/train/grapple/grapple51.csv', 'data/train/grapple/grapple52.csv', 'data/train/grapple/grapple53.csv', 'data/train/grapple/grapple54.csv', 'data/train/grapple/grapple55.csv', 'data/train/grapple/grapple56.csv', 'data/train/grapple/grapple57.csv', 'data/train/grapple/grapple58.csv', 'data/train/grapple/grapple59.csv', 'data/train/grapple/grapple6.csv', 'data/train/grapple/grapple7.csv', 'data/train/grapple/grapple8.csv', 'data/train/grapple/grapple9.csv']\n",
      "60\n",
      "[523.0784225463867, 445.8695983886719, 491.9159698486328, 411.30849838256836, 489.99401092529297, 358.9629364013672, 528.8862991333008, 329.9143409729004, 564.7311019897461, 322.9025173187256, 502.1125793457031, 302.07919120788574, 487.64110565185547, 246.26907348632812, 478.4663391113281, 212.6900339126587, 472.8984832763672, 182.89398193359375, 537.9697799682617, 301.32001876831055, 544.7367858886719, 238.221116065979, 550.5208969116211, 200.6710910797119, 557.3276901245117, 168.46293926239014, 565.3530120849609, 317.3664379119873, 588.4778594970703, 277.56382942199707, 578.7829971313477, 309.9401092529297, 569.8569107055664, 338.4822463989258, 585.7852554321289, 343.5926914215088, 595.5766677856445, 321.82886123657227, 582.4721527099609, 347.53698348999023, 572.3862838745117, 372.9672431945801]\n",
      "training set:\n",
      "2681\n",
      "2681\n",
      "start\n",
      "['data/test/start/start0.csv', 'data/test/start/start1.csv', 'data/test/start/start10.csv', 'data/test/start/start11.csv', 'data/test/start/start12.csv', 'data/test/start/start13.csv', 'data/test/start/start14.csv', 'data/test/start/start15.csv', 'data/test/start/start16.csv', 'data/test/start/start17.csv', 'data/test/start/start18.csv', 'data/test/start/start19.csv', 'data/test/start/start2.csv', 'data/test/start/start3.csv', 'data/test/start/start4.csv', 'data/test/start/start5.csv', 'data/test/start/start6.csv', 'data/test/start/start7.csv', 'data/test/start/start8.csv', 'data/test/start/start9.csv']\n",
      "20\n",
      "[199.9078369140625, 417.99665451049805, 160.78680038452148, 398.2474708557129, 132.04051971435547, 362.8988456726074, 113.22639465332031, 333.1591987609863, 93.55143547058105, 316.16432189941406, 161.02716445922852, 320.5876636505127, 143.92179489135742, 282.6318168640137, 133.02770614624023, 260.24831771850586, 124.84798431396484, 241.54343605041504, 186.40287399291992, 313.44703674316406, 181.43293380737305, 268.0399703979492, 177.7659797668457, 239.20509338378906, 175.48513412475586, 215.25133609771729, 209.02809143066406, 316.3128662109375, 211.5144920349121, 275.4481315612793, 212.76729583740234, 249.07648086547852, 213.20154190063477, 226.84813499450684, 229.52457427978516, 326.1486625671387, 246.00265502929688, 301.0513114929199, 256.6564750671387, 284.06956672668457, 265.2999687194824, 268.5326957702637]\n",
      "training set:\n",
      "288\n",
      "288\n",
      "turn\n",
      "['data/test/turn/turn27.csv', 'data/test/turn/turn41.csv', 'data/test/turn/turn42.csv', 'data/test/turn/turn43.csv', 'data/test/turn/turn44.csv', 'data/test/turn/turn45.csv', 'data/test/turn/turn46.csv', 'data/test/turn/turn47.csv', 'data/test/turn/turn48.csv', 'data/test/turn/turn49.csv', 'data/test/turn/turn50.csv', 'data/test/turn/turn51.csv', 'data/test/turn/turn52.csv', 'data/test/turn/turn53.csv', 'data/test/turn/turn54.csv', 'data/test/turn/turn55.csv', 'data/test/turn/turn56.csv', 'data/test/turn/turn57.csv', 'data/test/turn/turn58.csv', 'data/test/turn/turn59.csv']\n",
      "20\n",
      "[235.27971267700195, 407.3288154602051, 188.47759246826172, 387.6346778869629, 154.52136993408203, 354.5994758605957, 141.5087604522705, 320.45448303222656, 141.22715950012207, 288.8181495666504, 179.5400619506836, 310.8423328399658, 166.67861938476562, 284.5082187652588, 164.25418853759766, 313.37422370910645, 167.97252655029297, 340.06321907043457, 202.08637237548828, 308.5089683532715, 185.42606353759766, 282.6008605957031, 185.9343719482422, 318.89084815979004, 192.73401260375977, 346.7212200164795, 227.50938415527344, 309.83802795410156, 206.43321990966797, 282.18884468078613, 206.0459327697754, 319.27708625793457, 213.0295181274414, 348.0765438079834, 256.37332916259766, 316.3974094390869, 231.79798126220703, 297.6551055908203, 226.8906021118164, 323.6560535430908, 231.6636848449707, 346.0411262512207]\n",
      "training set:\n",
      "625\n",
      "625\n",
      "grapple\n",
      "['data/test/grapple/grapple0.csv', 'data/test/grapple/grapple1.csv', 'data/test/grapple/grapple10.csv', 'data/test/grapple/grapple11.csv', 'data/test/grapple/grapple12.csv', 'data/test/grapple/grapple13.csv', 'data/test/grapple/grapple14.csv', 'data/test/grapple/grapple15.csv', 'data/test/grapple/grapple16.csv', 'data/test/grapple/grapple17.csv', 'data/test/grapple/grapple18.csv', 'data/test/grapple/grapple19.csv', 'data/test/grapple/grapple2.csv', 'data/test/grapple/grapple3.csv', 'data/test/grapple/grapple4.csv', 'data/test/grapple/grapple5.csv', 'data/test/grapple/grapple6.csv', 'data/test/grapple/grapple7.csv', 'data/test/grapple/grapple8.csv', 'data/test/grapple/grapple9.csv']\n",
      "20\n",
      "[499.5969009399414, 370.4883670806885, 481.4578628540039, 337.8256416320801, 482.83260345458984, 296.5580177307129, 515.4885101318359, 272.74709701538086, 544.3595886230469, 263.67831230163574, 484.0217971801758, 261.49163246154785, 471.80397033691406, 220.13041019439697, 463.54381561279297, 195.19165992736816, 457.62054443359375, 174.27927017211914, 509.7914123535156, 263.92075538635254, 522.5543975830078, 216.9623851776123, 530.6150436401367, 189.42509651184082, 539.5200347900391, 166.1052417755127, 530.1497650146484, 277.89124488830566, 546.5873336791992, 258.140172958374, 534.3703460693359, 279.17750358581543, 526.2445068359375, 295.8584976196289, 545.4010009765625, 297.0326900482178, 554.5103454589844, 278.6026954650879, 545.9837341308594, 290.8545112609863, 540.9883117675781, 303.7998390197754]\n",
      "training set:\n",
      "1060\n",
      "1060\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "labels = {0: \"start\", 1: \"turn\", 2: \"grapple\"}\n",
    "\n",
    "Y_train = [] #1d array, (big_number, 1)\n",
    "X_train = [] #2d array, (big_number, 42)\n",
    "def data_append_train(data, X_train = X_train, Y_train = Y_train):\n",
    "  #formatting the labels, although I am not so sure what is required...\n",
    "  data1 = \"data/train\"\n",
    "  for label in labels: \n",
    "    name = labels[label]\n",
    "    path = f\"{data1}/{name}/*.csv\"\n",
    "    print(name)\n",
    "\n",
    "    # getting the directory\n",
    "    files = glob.glob(path)\n",
    "    print(files)\n",
    "    print(len(files))\n",
    "\n",
    "    # now concatenating the content of the files.\n",
    "    for f in files:\n",
    "        with open(f, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "        \n",
    "            i = 0\n",
    "            for row in csv_reader:\n",
    "                #skip the header line\n",
    "                if i == 0: \n",
    "                    i += 1\n",
    "                    continue\n",
    "                \n",
    "                X_train.append([float(num) for num in row])\n",
    "                Y_train.append(label)\n",
    "    \n",
    "    print(X_train[-1])\n",
    "    print(\"training set:\")\n",
    "    print(len(X_train))\n",
    "    print(len(Y_train))    \n",
    "\n",
    "Y_test = []\n",
    "X_test = []\n",
    "def data_append_test(data, X_test = X_test, Y_test = Y_test):\n",
    "  #formatting the labels, although I am not so sure what is required...\n",
    "  data1 = \"data/test\"\n",
    "  for label in labels: \n",
    "    name = labels[label]\n",
    "    path = f\"{data1}/{name}/*.csv\"\n",
    "    print(name)\n",
    "\n",
    "    # getting the directory\n",
    "    files = glob.glob(path)\n",
    "    print(files)\n",
    "    print(len(files))\n",
    "\n",
    "    # now concatenating the content of the files.\n",
    "    for f in files:\n",
    "        with open(f, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "        \n",
    "            i = 0\n",
    "            for row in csv_reader:\n",
    "                #skip the header line\n",
    "                if i == 0: \n",
    "                    i += 1\n",
    "                    continue\n",
    "                \n",
    "                X_test.append([float(num) for num in row])\n",
    "                Y_test.append(label)\n",
    "    \n",
    "    print(X_test[-1])\n",
    "    print(\"training set:\")\n",
    "    print(len(X_test))\n",
    "    print(len(Y_test))    \n",
    "#i'll only use the train test.\n",
    "data = \"data\"\n",
    "data_append_train(data)\n",
    "data_append_test(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since I already have the training dataset split, I just need to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[509.31186676, 459.92548943, 461.01940155, ..., 295.18349648,\n",
       "         528.78093719, 274.66890335],\n",
       "        [375.90648651, 256.53282166, 348.931427  , ..., 156.07103348,\n",
       "         386.70227051, 142.1629715 ],\n",
       "        [404.26086426, 426.70277596, 352.19688416, ..., 224.50306892,\n",
       "         444.31091309, 199.56587791],\n",
       "        ...,\n",
       "        [ 72.45704651, 233.24028969,  34.21592236, ...,  91.3131237 ,\n",
       "         129.16862488,  72.83489943],\n",
       "        [259.07169342, 410.95962524, 228.1410408 , ..., 360.01324654,\n",
       "         271.52738571, 361.98019981],\n",
       "        [603.2503891 , 189.52393055, 594.64172363, ..., 168.2949543 ,\n",
       "         640.63529968, 171.43424034]]),\n",
       " array([0, 0, 0, ..., 0, 1, 1]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_df_train = pd.DataFrame(X_train)\n",
    "# Y_df_train = pd.DataFrame(Y_train)\n",
    "\n",
    "# X_df_test = pd.DataFrame(X_test)\n",
    "# Y_df_test = pd.DataFrame(Y_test)\n",
    "\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "# \n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# the random_state is so that both shuffle perform the same.\n",
    "X_train,Y_train = shuffle(X_train, Y_train, random_state=0)\n",
    "X_test,Y_test = shuffle(X_test, Y_test, random_state=0)\n",
    "# X_train.shape, Y_train.shape\n",
    "X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "# model_save_path = \"model/\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"model/model.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    #everytime the accuracy gets better, it saves\n",
    "    save_freq='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#defining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Dense(units=32, activation='relu', input_shape=(42,)),\n",
    "    Dense(units=64, activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.l1_l2(0.05)),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    # Dropout(0.2),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=16, activation='relu', \n",
    "        kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
    "    # Dropout(0.2),\n",
    "    Dense(units=NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/84 [==========================>...] - ETA: 0s - loss: 19.0000 - accuracy: 0.5901INFO:tensorflow:Assets written to: model/model.01-0.81/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.01-0.81/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 3s 17ms/step - loss: 18.3560 - accuracy: 0.6125 - val_loss: 11.1146 - val_accuracy: 0.8066\n",
      "Epoch 2/150\n",
      "82/84 [============================>.] - ETA: 0s - loss: 9.0339 - accuracy: 0.9059INFO:tensorflow:Assets written to: model/model.02-0.89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.02-0.89/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 8.9998 - accuracy: 0.9068 - val_loss: 7.7695 - val_accuracy: 0.8896\n",
      "Epoch 3/150\n",
      "83/84 [============================>.] - ETA: 0s - loss: 6.5367 - accuracy: 0.9311INFO:tensorflow:Assets written to: model/model.03-0.89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.03-0.89/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 12ms/step - loss: 6.5314 - accuracy: 0.9314 - val_loss: 6.0425 - val_accuracy: 0.8943\n",
      "Epoch 4/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 5.4437 - accuracy: 0.9646 - val_loss: 5.4909 - val_accuracy: 0.8717\n",
      "Epoch 5/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.9824 - accuracy: 0.9593 - val_loss: 4.9898 - val_accuracy: 0.8670\n",
      "Epoch 6/150\n",
      "71/84 [========================>.....] - ETA: 0s - loss: 4.5825 - accuracy: 0.9679INFO:tensorflow:Assets written to: model/model.06-0.95/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.06-0.95/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 14ms/step - loss: 4.5436 - accuracy: 0.9687 - val_loss: 4.4178 - val_accuracy: 0.9481\n",
      "Epoch 7/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 4.2158 - accuracy: 0.9605 - val_loss: 4.1828 - val_accuracy: 0.9358\n",
      "Epoch 8/150\n",
      "78/84 [==========================>...] - ETA: 0s - loss: 3.8846 - accuracy: 0.9683INFO:tensorflow:Assets written to: model/model.08-0.95/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.08-0.95/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 3.8728 - accuracy: 0.9687 - val_loss: 3.7753 - val_accuracy: 0.9528\n",
      "Epoch 9/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 3.5953 - accuracy: 0.9672 - val_loss: 3.5021 - val_accuracy: 0.9283\n",
      "Epoch 10/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 3.3261 - accuracy: 0.9720 - val_loss: 3.2747 - val_accuracy: 0.9340\n",
      "Epoch 11/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 3.0958 - accuracy: 0.9668 - val_loss: 3.0526 - val_accuracy: 0.9255\n",
      "Epoch 12/150\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 2.8632 - accuracy: 0.9800INFO:tensorflow:Assets written to: model/model.12-0.95/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.12-0.95/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 12ms/step - loss: 2.8417 - accuracy: 0.9817 - val_loss: 2.8212 - val_accuracy: 0.9547\n",
      "Epoch 13/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.6703 - accuracy: 0.9765 - val_loss: 2.6759 - val_accuracy: 0.9283\n",
      "Epoch 14/150\n",
      "83/84 [============================>.] - ETA: 0s - loss: 2.5073 - accuracy: 0.9733INFO:tensorflow:Assets written to: model/model.14-0.96/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.14-0.96/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 2.5059 - accuracy: 0.9731 - val_loss: 2.4872 - val_accuracy: 0.9642\n",
      "Epoch 15/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.3405 - accuracy: 0.9784 - val_loss: 2.3706 - val_accuracy: 0.9453\n",
      "Epoch 16/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.1837 - accuracy: 0.9784 - val_loss: 2.2447 - val_accuracy: 0.9481\n",
      "Epoch 17/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.0788 - accuracy: 0.9720 - val_loss: 2.1502 - val_accuracy: 0.9217\n",
      "Epoch 18/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.9346 - accuracy: 0.9720 - val_loss: 2.1137 - val_accuracy: 0.8679\n",
      "Epoch 19/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8207 - accuracy: 0.9754 - val_loss: 1.9327 - val_accuracy: 0.9415\n",
      "Epoch 20/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6892 - accuracy: 0.9828 - val_loss: 1.7388 - val_accuracy: 0.9123\n",
      "Epoch 21/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5983 - accuracy: 0.9806 - val_loss: 1.7999 - val_accuracy: 0.8679\n",
      "Epoch 22/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.4996 - accuracy: 0.9828 - val_loss: 1.5248 - val_accuracy: 0.9623\n",
      "Epoch 23/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.3893 - accuracy: 0.9884 - val_loss: 1.4759 - val_accuracy: 0.9425\n",
      "Epoch 24/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.4103 - accuracy: 0.9627 - val_loss: 1.4446 - val_accuracy: 0.9538\n",
      "Epoch 25/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.9862 - val_loss: 1.2977 - val_accuracy: 0.9538\n",
      "Epoch 26/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.1587 - accuracy: 0.9862 - val_loss: 1.2088 - val_accuracy: 0.9632\n",
      "Epoch 27/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.1076 - accuracy: 0.9802 - val_loss: 1.1557 - val_accuracy: 0.9500\n",
      "Epoch 28/150\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 1.0184 - accuracy: 0.9867INFO:tensorflow:Assets written to: model/model.28-0.97/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.28-0.97/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 2s 23ms/step - loss: 1.0176 - accuracy: 0.9869 - val_loss: 1.0577 - val_accuracy: 0.9698\n",
      "Epoch 29/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.9380 - accuracy: 0.9899 - val_loss: 1.0110 - val_accuracy: 0.9491\n",
      "Epoch 30/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.9114 - accuracy: 0.9821 - val_loss: 1.0695 - val_accuracy: 0.8906\n",
      "Epoch 31/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.8687 - accuracy: 0.9847 - val_loss: 0.9377 - val_accuracy: 0.9443\n",
      "Epoch 32/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7950 - accuracy: 0.9843 - val_loss: 0.8964 - val_accuracy: 0.9425\n",
      "Epoch 33/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.9858 - val_loss: 0.9687 - val_accuracy: 0.9330\n",
      "Epoch 34/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.9817 - val_loss: 0.7638 - val_accuracy: 0.9670\n",
      "Epoch 35/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.9843 - val_loss: 0.7116 - val_accuracy: 0.9491\n",
      "Epoch 36/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.9892 - val_loss: 0.6863 - val_accuracy: 0.9547\n",
      "Epoch 37/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.9884 - val_loss: 0.6398 - val_accuracy: 0.9660\n",
      "Epoch 38/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.9892 - val_loss: 0.6892 - val_accuracy: 0.9217\n",
      "Epoch 39/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.9825 - val_loss: 0.5759 - val_accuracy: 0.9651\n",
      "Epoch 40/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.9795 - val_loss: 0.5755 - val_accuracy: 0.9670\n",
      "Epoch 41/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.9795 - val_loss: 0.5061 - val_accuracy: 0.9698\n",
      "Epoch 42/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.9828 - val_loss: 0.5168 - val_accuracy: 0.9604\n",
      "Epoch 43/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.9869 - val_loss: 0.5258 - val_accuracy: 0.9453\n",
      "Epoch 44/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.9836 - val_loss: 0.4686 - val_accuracy: 0.9594\n",
      "Epoch 45/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.9892 - val_loss: 0.4145 - val_accuracy: 0.9632\n",
      "Epoch 46/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.9888 - val_loss: 0.4094 - val_accuracy: 0.9632\n",
      "Epoch 47/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.9668 - val_loss: 0.4089 - val_accuracy: 0.9698\n",
      "Epoch 48/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9881 - val_loss: 0.3768 - val_accuracy: 0.9689\n",
      "Epoch 49/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.9888 - val_loss: 0.3616 - val_accuracy: 0.9689\n",
      "Epoch 50/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9918 - val_loss: 0.3502 - val_accuracy: 0.9679\n",
      "Epoch 51/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.9884 - val_loss: 0.3394 - val_accuracy: 0.9698\n",
      "Epoch 52/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9858 - val_loss: 0.3546 - val_accuracy: 0.9623\n",
      "Epoch 53/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9910 - val_loss: 0.3169 - val_accuracy: 0.9698\n",
      "Epoch 54/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9869 - val_loss: 0.4508 - val_accuracy: 0.9198\n",
      "Epoch 55/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9866 - val_loss: 0.2752 - val_accuracy: 0.9689\n",
      "Epoch 56/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9828 - val_loss: 0.3052 - val_accuracy: 0.9613\n",
      "Epoch 57/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9877 - val_loss: 0.2613 - val_accuracy: 0.9689\n",
      "Epoch 58/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9877 - val_loss: 0.2938 - val_accuracy: 0.9623\n",
      "Epoch 59/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9866 - val_loss: 0.2666 - val_accuracy: 0.9698\n",
      "Epoch 60/150\n",
      "58/84 [===================>..........] - ETA: 0s - loss: 0.2075 - accuracy: 0.9855INFO:tensorflow:Assets written to: model/model.60-0.97/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.60-0.97/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 17ms/step - loss: 0.2049 - accuracy: 0.9866 - val_loss: 0.2753 - val_accuracy: 0.9708\n",
      "Epoch 61/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9873 - val_loss: 0.2557 - val_accuracy: 0.9679\n",
      "Epoch 62/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9896 - val_loss: 0.2442 - val_accuracy: 0.9708\n",
      "Epoch 63/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9899 - val_loss: 0.2488 - val_accuracy: 0.9679\n",
      "Epoch 64/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9881 - val_loss: 0.2247 - val_accuracy: 0.9698\n",
      "Epoch 65/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9866 - val_loss: 0.2485 - val_accuracy: 0.9660\n",
      "Epoch 66/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9873 - val_loss: 0.2385 - val_accuracy: 0.9566\n",
      "Epoch 67/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9925 - val_loss: 0.2209 - val_accuracy: 0.9698\n",
      "Epoch 68/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9910 - val_loss: 0.2744 - val_accuracy: 0.9226\n",
      "Epoch 69/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9843 - val_loss: 0.2016 - val_accuracy: 0.9698\n",
      "Epoch 70/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9918 - val_loss: 0.2629 - val_accuracy: 0.9415\n",
      "Epoch 71/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9937 - val_loss: 0.2060 - val_accuracy: 0.9566\n",
      "Epoch 72/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9922 - val_loss: 0.3071 - val_accuracy: 0.9142\n",
      "Epoch 73/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9910 - val_loss: 0.3454 - val_accuracy: 0.8943\n",
      "Epoch 74/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9914 - val_loss: 0.3477 - val_accuracy: 0.8943\n",
      "Epoch 75/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9855 - val_loss: 0.2156 - val_accuracy: 0.9708\n",
      "Epoch 76/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9899 - val_loss: 0.3355 - val_accuracy: 0.9208\n",
      "Epoch 77/150\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 0.1405 - accuracy: 0.9884INFO:tensorflow:Assets written to: model/model.77-0.97/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.77-0.97/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 17ms/step - loss: 0.1391 - accuracy: 0.9888 - val_loss: 0.1959 - val_accuracy: 0.9736\n",
      "Epoch 78/150\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9862 - val_loss: 0.3456 - val_accuracy: 0.9075\n",
      "Epoch 79/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9869 - val_loss: 0.1903 - val_accuracy: 0.9736\n",
      "Epoch 80/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9940 - val_loss: 0.2564 - val_accuracy: 0.9415\n",
      "Epoch 81/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9881 - val_loss: 0.2431 - val_accuracy: 0.9255\n",
      "Epoch 82/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9884 - val_loss: 0.2110 - val_accuracy: 0.9642\n",
      "Epoch 83/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9855 - val_loss: 0.2452 - val_accuracy: 0.9208\n",
      "Epoch 84/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9907 - val_loss: 0.1765 - val_accuracy: 0.9698\n",
      "Epoch 85/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9832 - val_loss: 0.1954 - val_accuracy: 0.9717\n",
      "Epoch 86/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9873 - val_loss: 0.1858 - val_accuracy: 0.9717\n",
      "Epoch 87/150\n",
      "83/84 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9932INFO:tensorflow:Assets written to: model/model.87-0.98/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.87-0.98/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 18ms/step - loss: 0.0924 - accuracy: 0.9933 - val_loss: 0.1727 - val_accuracy: 0.9755\n",
      "Epoch 88/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9944 - val_loss: 0.1774 - val_accuracy: 0.9736\n",
      "Epoch 89/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9914 - val_loss: 0.2520 - val_accuracy: 0.9651\n",
      "Epoch 90/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9937 - val_loss: 0.2146 - val_accuracy: 0.9274\n",
      "Epoch 91/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9903 - val_loss: 0.1736 - val_accuracy: 0.9698\n",
      "Epoch 92/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9937 - val_loss: 0.2120 - val_accuracy: 0.9642\n",
      "Epoch 93/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9933 - val_loss: 0.2139 - val_accuracy: 0.9340\n",
      "Epoch 94/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9937 - val_loss: 0.1719 - val_accuracy: 0.9736\n",
      "Epoch 95/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9940 - val_loss: 0.1458 - val_accuracy: 0.9745\n",
      "Epoch 96/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9873 - val_loss: 0.1649 - val_accuracy: 0.9679\n",
      "Epoch 97/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9903 - val_loss: 0.2671 - val_accuracy: 0.9377\n",
      "Epoch 98/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9903 - val_loss: 0.1920 - val_accuracy: 0.9349\n",
      "Epoch 99/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9907 - val_loss: 0.1660 - val_accuracy: 0.9755\n",
      "Epoch 100/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9940 - val_loss: 0.1694 - val_accuracy: 0.9708\n",
      "Epoch 101/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9910 - val_loss: 0.2273 - val_accuracy: 0.9613\n",
      "Epoch 102/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9888 - val_loss: 0.3926 - val_accuracy: 0.8774\n",
      "Epoch 103/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9858 - val_loss: 0.2439 - val_accuracy: 0.9208\n",
      "Epoch 104/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9866 - val_loss: 0.1648 - val_accuracy: 0.9717\n",
      "Epoch 105/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9948 - val_loss: 0.1597 - val_accuracy: 0.9745\n",
      "Epoch 106/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9940 - val_loss: 0.1883 - val_accuracy: 0.9689\n",
      "Epoch 107/150\n",
      "56/84 [===================>..........] - ETA: 0s - loss: 0.1116 - accuracy: 0.9860INFO:tensorflow:Assets written to: model/model.107-0.98/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model.107-0.98/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1084 - accuracy: 0.9869 - val_loss: 0.1583 - val_accuracy: 0.9792\n",
      "Epoch 108/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9914 - val_loss: 0.1799 - val_accuracy: 0.9726\n",
      "Epoch 109/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9910 - val_loss: 0.2489 - val_accuracy: 0.9642\n",
      "Epoch 110/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9948 - val_loss: 0.1917 - val_accuracy: 0.9698\n",
      "Epoch 111/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9903 - val_loss: 0.3180 - val_accuracy: 0.9019\n",
      "Epoch 112/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9922 - val_loss: 0.2067 - val_accuracy: 0.9698\n",
      "Epoch 113/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9925 - val_loss: 0.2272 - val_accuracy: 0.9670\n",
      "Epoch 114/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9914 - val_loss: 0.1658 - val_accuracy: 0.9708\n",
      "Epoch 115/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9933 - val_loss: 0.1493 - val_accuracy: 0.9726\n",
      "Epoch 116/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9937 - val_loss: 0.1911 - val_accuracy: 0.9604\n",
      "Epoch 117/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9948 - val_loss: 0.2064 - val_accuracy: 0.9377\n",
      "Epoch 118/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9925 - val_loss: 0.2080 - val_accuracy: 0.9717\n",
      "Epoch 119/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9940 - val_loss: 0.3577 - val_accuracy: 0.9085\n",
      "Epoch 120/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.9862 - val_loss: 0.2320 - val_accuracy: 0.9226\n",
      "Epoch 121/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9851 - val_loss: 0.1678 - val_accuracy: 0.9708\n",
      "Epoch 122/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9877 - val_loss: 0.1502 - val_accuracy: 0.9726\n",
      "Epoch 123/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9907 - val_loss: 0.1469 - val_accuracy: 0.9736\n",
      "Epoch 124/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9944 - val_loss: 0.1870 - val_accuracy: 0.9670\n",
      "Epoch 125/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9944 - val_loss: 0.1404 - val_accuracy: 0.9774\n",
      "Epoch 126/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9918 - val_loss: 0.1952 - val_accuracy: 0.9585\n",
      "Epoch 127/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9873 - val_loss: 0.2079 - val_accuracy: 0.9566\n",
      "Epoch 128/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9668 - val_loss: 0.1849 - val_accuracy: 0.9698\n",
      "Epoch 129/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9940 - val_loss: 0.1563 - val_accuracy: 0.9717\n",
      "Epoch 130/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9948 - val_loss: 0.1896 - val_accuracy: 0.9557\n",
      "Epoch 131/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9948 - val_loss: 0.2028 - val_accuracy: 0.9425\n",
      "Epoch 132/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9933 - val_loss: 0.2036 - val_accuracy: 0.9679\n",
      "Epoch 133/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9959 - val_loss: 0.1897 - val_accuracy: 0.9679\n",
      "Epoch 134/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9925 - val_loss: 0.3502 - val_accuracy: 0.8868\n",
      "Epoch 135/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9821 - val_loss: 0.1659 - val_accuracy: 0.9708\n",
      "Epoch 136/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9952 - val_loss: 0.2216 - val_accuracy: 0.9509\n",
      "Epoch 137/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9840 - val_loss: 0.1918 - val_accuracy: 0.9670\n",
      "Epoch 138/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9858 - val_loss: 0.1952 - val_accuracy: 0.9670\n",
      "Epoch 139/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9869 - val_loss: 0.1712 - val_accuracy: 0.9689\n",
      "Epoch 140/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9843 - val_loss: 0.1801 - val_accuracy: 0.9698\n",
      "Epoch 141/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9862 - val_loss: 0.1753 - val_accuracy: 0.9679\n",
      "Epoch 142/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9836 - val_loss: 0.4221 - val_accuracy: 0.8925\n",
      "Epoch 143/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9840 - val_loss: 0.2028 - val_accuracy: 0.9632\n",
      "Epoch 144/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9914 - val_loss: 0.1496 - val_accuracy: 0.9717\n",
      "Epoch 145/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9877 - val_loss: 0.3723 - val_accuracy: 0.8481\n",
      "Epoch 146/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9910 - val_loss: 0.2253 - val_accuracy: 0.9594\n",
      "Epoch 147/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9933 - val_loss: 0.2607 - val_accuracy: 0.9349\n",
      "Epoch 148/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9888 - val_loss: 0.1624 - val_accuracy: 0.9717\n",
      "Epoch 149/150\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9899 - val_loss: 0.1573 - val_accuracy: 0.9726\n",
      "Epoch 150/150\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9940 - val_loss: 0.1852 - val_accuracy: 0.9642\n"
     ]
    }
   ],
   "source": [
    "#fitting\n",
    "history = model.fit(X_train,Y_train, epochs=150, batch_size=32, validation_data=(X_test,Y_test), callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
